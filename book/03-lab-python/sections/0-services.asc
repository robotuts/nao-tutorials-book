==== Использование сервисов

Создайте текстовый файл и назовите его, например, `main.py`. Рассмотрим следующий код:

[source,python]
.main.py
----
import qi

session = qi.Session()
session.connect("tcp://192.168.1.1:9559")
tts = session.service("ALTextToSpeech")
tts.say("Hello, World")
----

Данный скрипт является простейшим "Hello World" для Nao на `Python`. Укажите в строке `tcp://192.168.1.1:9559` актуальный адрес робота и запустите скрипт:

[source,bash]
----
python main.py
----

Робот должен произнести "Hello, World", а в консоли появится сообщение примерно следующего содержания:

[source,text]
----
[W] 1454940542.409989 1503 qi.path.sdklayout: No Application was created, trying to deduce paths
----

Данное предупреждение информирует о том, что в приложениях стоит явно указывать тип `Application` и вызывать его методы для открытия сессии. С использованием `Application` программа примет следующий вид:

[source,python]
.main.py
----
import qi
import sys

app = qi.Application(sys.argv)
app.start()
tts = app.session.service("ALTextToSpeech")
tts.say("Hello, World")
----

Обратите внимание на то, что теперь вместо явного указания информации для подключения используется `sys.arg`, это связано с архитектурой библиотеки `libqi-python`. В данном случае адрес робота указывается при запуске скрипта:

[source,bash]
----
python main.py --qi-url=tcp://192.168.1.1:9559
----

Результат работы скрипта не отличается от предыдущего, но больше предупреждение появляться не должно.

Помимо `ALTextToSpeech` существуют и другие модули сервисы. С полным списком можно ознакомиться в документации по адресу http://doc.aldebaran.com/2-1/naoqi/index.html#naoqi-api.

Рассмотрим пример с несколькими сервисами одновременно:

[source,python]
.main.py
----
import qi
import sys

app = qi.Application(sys.argv)
app.start()

tts = app.session.service("ALTextToSpeech")     # <1>
motion = app.session.service("ALMotion")        # <2>
posture = app.session.service("ALRobotPosture") # <3>

motion.wakeUp()
posture.goToPosture("Stand", 1.0)
tts.say("Hello, my name is Nao!")
motion.rest()
----
<1> речевая функция
<2> управление движением робота
<3> управление позами робота

Алгоритм действий робота следующий:

. Запускаются все моторы робота функцией `wakeUp()` сервиса `ALMotion` (в _Choregraphe_ -- `stiffness`).
. Робот принимает позу `Stand` (т.е. встает, если сидел).
. Робот произносит `Hello, my name is Nao`.
. Моторы снова отключаются

Данный пример описывает создание последовательных действий в роботе, каждое действие является _блокирующим_, т.е. пока оно не выполнится -- следующее не наступит. Добавим параллельное действие:

[source,python]
.main.py
----
import qi
import sys

HEY_ANIMATION_1 = "animations/Stand/Gestures/Hey_1"

app = qi.Application(sys.argv)
app.start()

tts = app.session.service("ALTextToSpeech")
motion = app.session.service("ALMotion")
posture = app.session.service("ALRobotPosture")
bhm = app.session.service("ALBehaviorManager")

motion.wakeUp()
posture.goToPosture("Stand", 1.0)
animation = bhm.runBehavior(HEY_ANIMATION_1, _async=True)
tts.say("Hello, my name is Nao!")
animation.value()
posture.goToPosture("Sit", 1.0)
tts.say("Bye-bye")
motion.rest()
----

Первая часть алгоритма не изменилась, но функция +runBehaviour()+ вызывается с ключом `$$_$$async=True`, которое производит действие _асинхронно_. В данном случае робот помашет рукой и одновременно произнесет `Hello, my name is Nao`. Ожидание выполнения действия осуществляется в строке `animation.value()`, после нее действия снова становятся последовательными.
